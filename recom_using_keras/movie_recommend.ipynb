{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/collaborative_recommendation_system/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/collaborative_recommendation_system/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1106635946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres  \\\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "\n",
       "   userId  rating   timestamp  \n",
       "0       1     4.0   964982703  \n",
       "1       5     4.0   847434962  \n",
       "2       7     4.5  1106635946  \n",
       "3      15     2.5  1510577970  \n",
       "4      17     4.5  1305696483  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = movies_df.merge(ratings_df, on=[\"movieId\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float64, name=None)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.array(merged_df[\"rating\"].values.tolist())\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9742 non-null   int64 \n",
      " 1   title    9742 non-null   object\n",
      " 2   genres   9742 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(6,), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movies = movies_df.values.tolist()\n",
    "import numpy as np\n",
    "movies = tf.data.Dataset.from_tensor_slices(np.array(merged_df.values.tolist()))\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "class Model(tfrs.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user representation.\n",
    "    self.user_model = tf.keras.layers.Embedding(\n",
    "        input_dim=2000, output_dim=64)\n",
    "    # Set up movie representation.\n",
    "    self.item_model = tf.keras.layers.Embedding(\n",
    "        input_dim=2000, output_dim=64)\n",
    "    # Set up a retrieval task and evaluation metrics over the\n",
    "    # entire dataset of candidates.\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.item_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.item_model(features[\"movie_id\"])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/05/mz9vyrj559z6gnm1ptm7x5z80000gq/T/ipykernel_19079/3961122226.py\", line 23, in compute_loss\n        user_embeddings = self.user_model(features[\"user_id\"])\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'user_id'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000020?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train\u001b[39m.\u001b[39;49mbatch(\u001b[39m4096\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/health/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/05/mz9vyrj559z6gnm1ptm7x5z80000gq/T/__autograph_generated_filemywu9r2i.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/health/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inputs, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "\u001b[1;32m/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb Cell 10'\u001b[0m in \u001b[0;36mModel.compute_loss\u001b[0;34m(self, features, training)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000013?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\u001b[39mself\u001b[39m, features: Dict[Text, tf\u001b[39m.\u001b[39mTensor], training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000013?line=22'>23</a>\u001b[0m   user_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_model(features[\u001b[39m\"\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000013?line=23'>24</a>\u001b[0m   movie_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_model(features[\u001b[39m\"\u001b[39m\u001b[39mmovie_id\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000013?line=25'>26</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask(user_embeddings, movie_embeddings)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/prajualpillai/miniforge3/envs/health/lib/python3.9/site-packages/tensorflow_recommenders/models/base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"/var/folders/05/mz9vyrj559z6gnm1ptm7x5z80000gq/T/ipykernel_19079/3961122226.py\", line 23, in compute_loss\n        user_embeddings = self.user_model(features[\"user_id\"])\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'user_id'\n"
     ]
    }
   ],
   "source": [
    "model.fit(train.batch(4096), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='movielens',\n",
       "    full_name='movielens/100k-ratings/0.1.1',\n",
       "    description=\"\"\"\n",
       "    This dataset contains a set of movie ratings from the MovieLens website, a movie\n",
       "    recommendation service. This dataset was collected and maintained by [GroupLens]\n",
       "    (https://grouplens.org/), a research group at the University of Minnesota. There\n",
       "    are 5 versions included: \"25m\", \"latest-small\", \"100k\", \"1m\", \"20m\". In all\n",
       "    datasets, the movies data and ratings data are joined on \"movieId\". The 25m\n",
       "    dataset, latest-small dataset, and 20m dataset contain only movie data and\n",
       "    rating data. The 1m dataset and 100k dataset contain demographic data in\n",
       "    addition to movie and rating data.\n",
       "    \n",
       "    - \"25m\": This is the latest stable version of the MovieLens dataset. It is\n",
       "    recommended for research purposes.\n",
       "    - \"latest-small\": This is a small subset of the latest version of the MovieLens\n",
       "    dataset. It is changed and updated over time by GroupLens.\n",
       "    - \"100k\": This is the oldest version of the MovieLens datasets. It is a small\n",
       "    dataset with demographic data.\n",
       "    - \"1m\": This is the largest MovieLens dataset that contains demographic data.\n",
       "    - \"20m\": This is one of the most used MovieLens datasets in academic papers\n",
       "    along with the 1m dataset.\n",
       "    \n",
       "    For each version, users can view either only the movies data by adding the\n",
       "    \"-movies\" suffix (e.g. \"25m-movies\") or the ratings data joined with the movies\n",
       "    data (and users data in the 1m and 100k datasets) by adding the \"-ratings\"\n",
       "    suffix (e.g. \"25m-ratings\").\n",
       "    \n",
       "    The features below are included in all versions with the \"-ratings\" suffix.\n",
       "    \n",
       "    - \"movie_id\": a unique identifier of the rated movie\n",
       "    - \"movie_title\": the title of the rated movie with the release year in\n",
       "    parentheses\n",
       "    - \"movie_genres\": a sequence of genres to which the rated movie belongs\n",
       "    - \"user_id\": a unique identifier of the user who made the rating\n",
       "    - \"user_rating\": the score of the rating on a five-star scale\n",
       "    - \"timestamp\": the timestamp of the ratings, represented in seconds since\n",
       "    midnight Coordinated Universal Time (UTC) of January 1, 1970\n",
       "    \n",
       "    The \"100k-ratings\" and \"1m-ratings\" versions in addition include the following\n",
       "    demographic features.\n",
       "    \n",
       "    - \"user_gender\": gender of the user who made the rating; a true value\n",
       "    corresponds to male\n",
       "    - \"bucketized_user_age\": bucketized age values of the user who made the rating,\n",
       "    the values and the corresponding ranges are:\n",
       "      - 1: \"Under 18\"\n",
       "      - 18: \"18-24\"\n",
       "      - 25: \"25-34\"\n",
       "      - 35: \"35-44\"\n",
       "      - 45: \"45-49\"\n",
       "      - 50: \"50-55\"\n",
       "      - 56: \"56+\"\n",
       "    - \"user_occupation_label\": the occupation of the user who made the rating\n",
       "    represented by an integer-encoded label; labels are preprocessed to be\n",
       "    consistent across different versions\n",
       "    - \"user_occupation_text\": the occupation of the user who made the rating in\n",
       "    the original string; different versions can have different set of raw text\n",
       "    labels\n",
       "    - \"user_zip_code\": the zip code of the user who made the rating\n",
       "    \n",
       "    In addition, the \"100k-ratings\" dataset would also have a feature \"raw_user_age\"\n",
       "    which is the exact ages of the users who made the rating\n",
       "    \n",
       "    Datasets with the \"-movies\" suffix contain only \"movie_id\", \"movie_title\", and\n",
       "    \"movie_genres\" features.\n",
       "    \"\"\",\n",
       "    config_description=\"\"\"\n",
       "    This dataset contains 100,000 ratings from 943 users on 1,682\n",
       "    movies. This dataset is the oldest version of the MovieLens\n",
       "    dataset.\n",
       "    \n",
       "    Each user has rated at least 20 movies. Ratings are in whole-star\n",
       "    increments. This dataset contains demographic data of users in\n",
       "    addition to data on movies and ratings.\n",
       "    \"\"\",\n",
       "    homepage='https://grouplens.org/datasets/movielens/',\n",
       "    data_path='~/tensorflow_datasets/movielens/100k-ratings/0.1.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=4.70 MiB,\n",
       "    dataset_size=32.41 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'bucketized_user_age': tf.float32,\n",
       "        'movie_genres': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=21)),\n",
       "        'movie_id': tf.string,\n",
       "        'movie_title': tf.string,\n",
       "        'raw_user_age': tf.float32,\n",
       "        'timestamp': tf.int64,\n",
       "        'user_gender': tf.bool,\n",
       "        'user_id': tf.string,\n",
       "        'user_occupation_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=22),\n",
       "        'user_occupation_text': tf.string,\n",
       "        'user_rating': tf.float32,\n",
       "        'user_zip_code': tf.string,\n",
       "    }),\n",
       "    supervised_keys=None,\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'train': <SplitInfo num_examples=100000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{10.1145/2827872,\n",
       "    author = {Harper, F. Maxwell and Konstan, Joseph A.},\n",
       "    title = {The MovieLens Datasets: History and Context},\n",
       "    year = {2015},\n",
       "    issue_date = {January 2016},\n",
       "    publisher = {Association for Computing Machinery},\n",
       "    address = {New York, NY, USA},\n",
       "    volume = {5},\n",
       "    number = {4},\n",
       "    issn = {2160-6455},\n",
       "    url = {https://doi.org/10.1145/2827872},\n",
       "    doi = {10.1145/2827872},\n",
       "    journal = {ACM Trans. Interact. Intell. Syst.},\n",
       "    month = dec,\n",
       "    articleno = {19},\n",
       "    numpages = {19},\n",
       "    keywords = {Datasets, recommendations, ratings, MovieLens}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, info = tfds.load('movielens/100k-ratings', split=\"train\", with_info=True)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = sample.map(lambda x: tf.strings.to_number(x[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0, 'movie_genres': array([7]), 'movie_id': b'357', 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\", 'raw_user_age': 46.0, 'timestamp': 879024327, 'user_gender': True, 'user_id': b'138', 'user_occupation_label': 4, 'user_occupation_text': b'doctor', 'user_rating': 4.0, 'user_zip_code': b'53211'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 16:07:07.424798: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in sample.take(1).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'take'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m movies\u001b[39m.\u001b[39;49mtake(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mas_numpy_iterator():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/prajualpillai/Desktop/prajual/Personal_git/Recommendation_system/recom_using_keras/movie_recommend.ipynb#ch0000015?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'take'"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_t = movies_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('health')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48119303730639014cfab26a35c02f31b83594fdfdd7d13cdbb1156f3533be6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
